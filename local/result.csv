,Title,Patent Number,Abstract,Classification,Inventors,Current Assignee,All Content
1365,Large-vocabulary speech recognition using an integrated syntactic and semantic statistical language model,US5839106A,"Methods and apparatus for performing large-vocabulary speech recognition employing an integrated syntactic and semantic statistical language model. In an exemplary embodiment, a stochastic language model is developed using a hybrid paradigm in which latent semantic analysis is combined with, and subordinated to, a conventional n-gram paradigm. The hybrid paradigm provides an estimate of the likelihood that a particular word, chosen from an underlying vocabulary will occur given a prevailing contextual history. The estimate is computed as a conditional probability that a word will occur given an ""integrated"" history combining an n-word, syntactic-type history with a semantic-type history based on a much larger contextual framework. Thus, the exemplary embodiment seamlessly blends local language structures with global usage patterns to provide, in a single language model, the proficiency of a short-horizon, syntactic model with the large-span effectiveness of semantic analysis.","G10L15/1815 Semantic context, e.g. disambiguation of the recognition hypotheses based on word meaningView 1 more classifications","Jerome R, Bellegarda",Apple Inc,"Large-vocabulary speech recognition using an integrated syntactic and semantic statistical language modelJerome R, BellegardaApple IncMethods and apparatus for performing large-vocabulary speech recognition employing an integrated syntactic and semantic statistical language model. In an exemplary embodiment, a stochastic language model is developed using a hybrid paradigm in which latent semantic analysis is combined with, and subordinated to, a conventional n-gram paradigm. The hybrid paradigm provides an estimate of the likelihood that a particular word, chosen from an underlying vocabulary will occur given a prevailing contextual history. The estimate is computed as a conditional probability that a word will occur given an ""integrated"" history combining an n-word, syntactic-type history with a semantic-type history based on a much larger contextual framework. Thus, the exemplary embodiment seamlessly blends local language structures with global usage patterns to provide, in a single language model, the proficiency of a short-horizon, syntactic model with the large-span effectiveness of semantic analysis."
1378,Dynamic language model for speech recognition,US5384892A,"A method of speech recognition which determines acoustic features in a sound sample; recognizes words comprising the acoustic features based on a language model, which determines the possible sequences of words that may be recognized; and the selection of an appropriate response based on the words recognized. Information about what words may be recognized, under which conditions those words may be recognized, and what response is appropriate when the words are recognized, is stored, in a preferred embodiment, in a data structure called a speech rule. These speech rules are partitioned according to the context in which they are active. When speech is detected, concurrent with acoustic feature extraction, the current state of the computer system is used to determine which rules are active and how they are to be combined in order to generate a language model for word recognition. A language model is dynamically generated and used to find the best interpretation of the acoustic features as a word sequence. This word sequence is then matched against active rules in order to determine the appropriate response. Rules that match all or part of the word sequence contribute data structures representing the ""meaning"" of the word sequence, and these data structures are used by the rule actions in order to generate an appropriate response to the spoken utterance.","G10L15/193 Formal grammars, e.g. finite state automata, context free grammars or word networksView 1 more classifications","Robert D, Strong",Apple Inc,"Dynamic language model for speech recognitionRobert D, StrongApple IncA method of speech recognition which determines acoustic features in a sound sample; recognizes words comprising the acoustic features based on a language model, which determines the possible sequences of words that may be recognized; and the selection of an appropriate response based on the words recognized. Information about what words may be recognized, under which conditions those words may be recognized, and what response is appropriate when the words are recognized, is stored, in a preferred embodiment, in a data structure called a speech rule. These speech rules are partitioned according to the context in which they are active. When speech is detected, concurrent with acoustic feature extraction, the current state of the computer system is used to determine which rules are active and how they are to be combined in order to generate a language model for word recognition. A language model is dynamically generated and used to find the best interpretation of the acoustic features as a word sequence. This word sequence is then matched against active rules in order to determine the appropriate response. Rules that match all or part of the word sequence contribute data structures representing the ""meaning"" of the word sequence, and these data structures are used by the rule actions in order to generate an appropriate response to the spoken utterance."
1387,Automatic language identification for dynamic text processing,US9946706B2,"Methods and systems which utilize, in one embodiment, automatic language identification, including automatic language identification for dynamic text processing. In at least certain embodiments, automatic language identification can be applied to spellchecking in real time as the user types.",G06F17/275 Language IdentificationView 2 more classifications,"Douglas R, DavidsonAli Ozer",Apple Inc,"Automatic language identification for dynamic text processingDouglas R, DavidsonAli OzerApple IncMethods and systems which utilize, in one embodiment, automatic language identification, including automatic language identification for dynamic text processing. In at least certain embodiments, automatic language identification can be applied to spellchecking in real time as the user types."
1482,Language translation for real-time text-based conversations,US5987401A,"A real-time language translation technique for text-based conversations. The messages forming the text-based conversation amongst a plurality of participants to the conversation are translated in real-time either from a user language to a conversation language of the conversation, or from the conversation language to the user language. The result is that the user is able to seamlessly converse in a text-based conversation (in the conversation language) using a language other than the conversation language. The invention is particularly advantageous for on-line text-based conversations, wherein users of on-line text-based conversations are able to seamlessly converse with each other in different languages.",H04L12/1827 Network arrangements for conference optimisation or adaptationView 1 more classifications,"John R, Trudeau",Apple Inc,"Language translation for real-time text-based conversationsJohn R, TrudeauApple IncA real-time language translation technique for text-based conversations. The messages forming the text-based conversation amongst a plurality of participants to the conversation are translated in real-time either from a user language to a conversation language of the conversation, or from the conversation language to the user language. The result is that the user is able to seamlessly converse in a text-based conversation (in the conversation language) using a language other than the conversation language. The invention is particularly advantageous for on-line text-based conversations, wherein users of on-line text-based conversations are able to seamlessly converse with each other in different languages."
1508,Method for disambiguating multiple readings in language conversion,US8706472B2,"Disambiguating multiple readings in language conversion is disclosed, including: receiving an input data to be converted into a set of characters comprising a symbolic representation of the input data in a target symbolic system; and using a language model that distinguishes between a first reading and a second reading of a character of the target symbolic system to determine a probability that the heteronymous character should be used to represent a corresponding portion of the input data.",G06F17/2863 Processing of non-latin text,"Brent D, RamerthDevang K, NaikDouglas R, DavidsonJannes G, A, DolfingJia Pu",Apple Inc,"Method for disambiguating multiple readings in language conversionBrent D, RamerthDevang K, NaikDouglas R, DavidsonJannes G, A, DolfingJia PuApple IncDisambiguating multiple readings in language conversion is disclosed, including: receiving an input data to be converted into a set of characters comprising a symbolic representation of the input data in a target symbolic system; and using a language model that distinguishes between a first reading and a second reading of a character of the target symbolic system to determine a probability that the heteronymous character should be used to represent a corresponding portion of the input data."
